{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Customer Data\n",
    "  Should be applicable to all customer data sets,\n",
    "  Explores categories as well as time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import datasets, svm, metrics\n",
    "from pandas import DataFrame\n",
    "import matplotlib as mpl\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Tuple\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# get nltk and corpus\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# get scapy and corpus\n",
    "import spacy\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import seaborn as sns\n",
    "import humanize\n",
    "import swifter\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot wider\n",
    "height_in_inches = 10\n",
    "matplotlib.rc(\"figure\", figsize=(2 * height_in_inches, height_in_inches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Export Data from healthkit using [qs-access](https://itunes.apple.com/us/app/qs-access/id920297614?mt=8) app\n",
    "# raw_csv= \"/home/idvorkin/data/wamd.all.csv\"\n",
    "raw_csv = \"/Users/idvorkin/imessage/all.messages.csv\"\n",
    "cleaned_df_pickled = f\"{raw_csv}.pickle\"\n",
    "\n",
    "\n",
    "# Load+Clean+Explore data using Dask as it's got multi-core.\n",
    "# Then convert to a pandas dataframe pickle.\n",
    "# df = dd.read_csv(raw_csv,sep='\\t' )\n",
    "# df = df.compute()\n",
    "# df = pd.read_csv(raw_csv,sep='\\t')\n",
    "df = pd.read_csv(raw_csv, sep=\"|\", lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up some  data\n",
    "\n",
    "# setup date column\n",
    "df[\"datetime\"] = pd.to_datetime(df.date_uct, errors=\"coerce\")\n",
    "df = df.set_index(df.datetime)\n",
    "\n",
    "# setup customer id\n",
    "df[\"customer_id\"] = df.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.compute()\n",
    "# df.to_pickle(cleaned_df_pickled)\n",
    "df = pd.read_pickle(cleaned_df_pickled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# gotta be a more elegant way, but doing this for now\n",
    "distribs = [\n",
    "    df[c].value_counts(normalize=True).apply(lambda d: d * 100) for c in df.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def isFlatDistribution(d):\n",
    "    return len(d) == 0 or d.iloc[0] < 0.01\n",
    "\n",
    "\n",
    "for d in sorted(\n",
    "    [d for d in distribs if not isFlatDistribution(d)], key=lambda d: d.iloc[0] * -1\n",
    "):\n",
    "    column_header = f\"\\n------ {d.name} ----- \"\n",
    "    print(column_header)\n",
    "    print(f\"{d.head(10)}\")\n",
    "\n",
    "print(\"++Flat distribution++\")\n",
    "for d in sorted([d for d in distribs if isFlatDistribution(d)], key=lambda d: d.name):\n",
    "    c = d.name\n",
    "    print(c)\n",
    "print(\"--Flat distribution--\")\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any time series data interesting beyond count()? Perhaps purchaces?\n",
    "# df.offer_accepted_flg, df.offer_asin_cnt, has_purchase_flg,device_family, device_type_id\n",
    "# https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/\n",
    "sns.set(rc={\"figure.figsize\": (11, 4)})\n",
    "count_hourly = df.resample(\"M\").count()\n",
    "count_hourly.iloc[:, 0].plot(title=\"Interactions over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_for(df, columns, minimum_call_count=0):\n",
    "    cid = \"customer_id\"\n",
    "    original_customer_by_count = df[cid].value_counts()\n",
    "    cid_to_exclude = original_customer_by_count[\n",
    "        original_customer_by_count.values <= minimum_call_count\n",
    "    ].index.values\n",
    "    df = df[~df.customer_id.isin(cid_to_exclude)]\n",
    "    customer_by_count = df[cid].value_counts()\n",
    "    dfT = (\n",
    "        customer_by_count.value_counts(normalize=True)\n",
    "        .apply(lambda d: d * 100)\n",
    "        .iloc[:columns]\n",
    "    )\n",
    "    dfT.index.name = f\"% usages by customer\"\n",
    "    N = len(customer_by_count.value_counts())\n",
    "    graphed = int(dfT.sum())\n",
    "    title = \"What % of time do customers call K times? \"\n",
    "    sub_title = f\"Universe customers calling >= {minimum_call_count} times, N={humanize.intcomma(N)}, Visible={graphed}%\"\n",
    "    ax = dfT.plot(kind=\"bar\", title=f\"{title}\\n{sub_title}\")\n",
    "    ax.set_ylabel(f\"% customers\")\n",
    "    plt.show()  # force the plot ot show\n",
    "\n",
    "\n",
    "plot_distribution_for(df, 3, 0)\n",
    "plot_distribution_for(df, 10, 3)\n",
    "plot_distribution_for(df, 10, 10)\n",
    "plot_distribution_for(df, 10, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAU/WAU/DAU analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw away all customers who only call once.\n",
    "\n",
    "# for remaining customers group into time index,\n",
    "# pivot (cidx time_index)\n",
    "#      | tindex_1 | tindex_2 | tindex_3| sum\n",
    "# cid1 |\n",
    "# sum along cid\n",
    "# if sum matches like clos to column index call them the right value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "customer_by_count = df.customer_id.value_counts()\n",
    "print(f\"customer_by_count\\n{customer_by_count.head(10)}\")\n",
    "# customer_by_count =  customer_by_count\n",
    "# df.obf_customer_id.value_counts().head(20)\n",
    "start_range = 0\n",
    "irange = range(start_range, start_range + 10)\n",
    "print(f\"customer_in_range\\n{customer_by_count.iloc[irange]}\")\n",
    "\n",
    "df_hc = df[df.customer_id.isin(customer_by_count.index[irange].values)]\n",
    "# count_hourly = df_hc.customer_id.resample(\"W\").count()\n",
    "# count_hourly = df_hc['2019-01':'2019-05'][[\"customer_id\"]].groupby(\"customer_id\").resample('D').count()\n",
    "count_hourly\n",
    "# count_hourly.plot()\n",
    "\n",
    "## TODO: Head customer behavior\n",
    "## TODO Middle\n",
    "## TODO: Tail removal\n",
    "\n",
    "## Look at head vs tail\n",
    "\n",
    "# See step functions Called O-10\n",
    "# Top 10 customers,\n",
    "# trange = range(0, 3)\n",
    "# customer_by_count.value_counts(normalize=True).apply(lambda d:d).iloc[trange] # .plot(kind='pie', title=f'% customer {trange}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# pd.pivot_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# df_hc.pivot_table([cid]).count()\n",
    "# df_hc.pivot_table(cid,aggfunc='count')\n",
    "freq = \"M\"\n",
    "cid_by_date = df_hc[\"2019\":].pivot_table(\n",
    "    values=\"datetime\",\n",
    "    index=[\"customer_id\"],\n",
    "    columns=pd.Grouper(freq=freq),\n",
    "    aggfunc=\"count\",\n",
    ")\n",
    "cid_sorted_by_sum = cid_by_date.T.sum().sort_values(ascending=False).index\n",
    "# cid_by_date = cid_by_date.sort_values(\"customer_id\")\n",
    "cid_by_date.T[cid_sorted_by_sum[:4]].plot()\n",
    "# cid_by_date.T.count().sort_values()\n",
    "# df_hc.pivot_table(index=[\"customer_id\"], columns=pd.Grouper(freq=freq), aggfunc=\"count\")[ \"customer_id\" ].T.plot(title=f\"customer {irange} by freq={freq}\", figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
