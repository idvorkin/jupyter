{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Customer Data\n",
    "  Should be applicable to all customer data sets,\n",
    "  Explores categories as well as time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import datasets, svm, metrics\n",
    "from pandas import DataFrame\n",
    "import matplotlib as mpl\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "# from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# get nltk and corpus\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# get scapy and corpus\n",
    "# import spacy\n",
    "# import time\n",
    "# from functools import lru_cache\n",
    "import seaborn as sns\n",
    "import humanize\n",
    "\n",
    "# import swifter\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from IPython.display import display\n",
    "\n",
    "from humanize import intcomma, intword\n",
    "import pandas_profiling\n",
    "import arrow\n",
    "import datetime\n",
    "from functools import partial\n",
    "from pandas_util import time_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot wider\n",
    "height_in_inches = 10\n",
    "matplotlib.rc(\"figure\", figsize=(2 * height_in_inches, height_in_inches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#raw_csv = \"~/data/wamd.all.csv\"\n",
    "raw_csv = \"~/data/all.messages.csv\"\n",
    "cleaned_df_pickled = f\"{os.path.expanduser(raw_csv)}.pickle.gz\"\n",
    "\n",
    "\n",
    "# Load+Clean+Explore data using Dask as it's got multi-core.\n",
    "# Then convert to a pandas dataframe pickle.\n",
    "# df = dd.read_csv(raw_csv,sep='\\t' )\n",
    "# df = df.compute()\n",
    "# df = pd.read_csv(raw_csv,sep='\\t')\n",
    "# df = pd.read_csv(raw_csv, sep=\"|\", lineterminator=\"\\n\", error_bad_lines=False)\n",
    "# df = pd.read_csv(raw_csv, sep=\"\\t\", lineterminator='\\r\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up some  data\n",
    "\n",
    "datetimeColumnName, customerIdColumnName = \"date_uct\", \"id\"\n",
    "\n",
    "# setup date column\n",
    "df[\"datetime\"] = pd.to_datetime(df[datetimeColumnName], errors=\"coerce\")\n",
    "df = df.set_index(df.datetime)\n",
    "# setup customer id\n",
    "df[\"customer_id\"] = df[customerIdColumnName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.compute()\n",
    "#df.to_pickle(cleaned_df_pickled)\n",
    "ti = time_it(f\"Load dataframe:{cleaned_df_pickled}\")\n",
    "df = pd.read_pickle(cleaned_df_pickled)\n",
    "ti.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# df = df.compute()\n",
    "# df.to_pickle(cleaned_df_pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.compute()\n",
    "# df.to_pickle(cleaned_df_pickled)\n",
    "# df.set_index\n",
    "# df = df.reset_index(drop=True)\n",
    "# kdf.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis -\n",
    "### Home Grown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# gotta be a more elegant way, but doing this for now\n",
    "\n",
    "ti = time_it(\"compute distribution\")\n",
    "distribs = [df[c].value_counts(normalize=True).toPercent() for c in df.columns]\n",
    "ti.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFlatDistribution(d):\n",
    "    return len(d) == 0 or d.iloc[0] < 0.01\n",
    "\n",
    "\n",
    "for d in sorted(\n",
    "    [d for d in distribs if not isFlatDistribution(d)], key=lambda d: d.iloc[0] * -1\n",
    "):\n",
    "    column_header = f\"\\n------ {d.name} ----- \"\n",
    "    print(column_header)\n",
    "    print(f\"{d.head(10)}\")\n",
    "\n",
    "print(\"++Flat distribution++\")\n",
    "for d in sorted([d for d in distribs if isFlatDistribution(d)], key=lambda d: d.name):\n",
    "    c = d.name\n",
    "    print(c)\n",
    "print(\"--Flat distribution--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis -\n",
    "### Like the grown ups do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks pretty crappy on a black background, maybe change color first\n",
    "# Also, I've had trouble with date indexes, might need to drop the index\n",
    "# df = df.reset_index(drop = True)\n",
    "profile_filename = \"output.html\"\n",
    "#ti = time_it(f\"profiling dataframe to {profile_filename}\")\n",
    "#pr = df.reset_index(drop=True).profile_report()\n",
    "#pr.to_file(output_file=profile_filename)\n",
    "#pr\n",
    "ti.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_for(df, count_buckets, minimum_call_count=0):\n",
    "    cid = \"customer_id\"\n",
    "    usage_by_cid = df[cid].value_counts()\n",
    "    cid_to_exclude = usage_by_cid[\n",
    "        usage_by_cid.values <= minimum_call_count\n",
    "    ].index.values\n",
    "    df = df[~df.customer_id.isin(cid_to_exclude)]\n",
    "    usage_by_cid = df[cid].value_counts()\n",
    "    dfT = usage_by_cid.value_counts(normalize=True).toPercent().iloc[:count_buckets]\n",
    "    dfT.index.name = f\"% usages by customer\"\n",
    "    N = len(usage_by_cid.value_counts())\n",
    "    graphed = int(dfT.sum())\n",
    "    title = \"What % of time do customers call K times? \"\n",
    "    sub_title = f\"Universe customers calling >= {minimum_call_count} times, N={humanize.intcomma(N)}, Visible={graphed}%\"\n",
    "    ax = dfT.plot(kind=\"bar\", title=f\"{title}\\n{sub_title}\")\n",
    "    ax.set_ylabel(f\"% customers\")\n",
    "    plt.show()  # force the plot ot show\n",
    "\n",
    "\n",
    "# create a df w/only multi users for faster analysis\n",
    "def df_w_multi_customers(df):\n",
    "    usage_by_cid = df.customer_id.value_counts()\n",
    "    cid_to_exclude = usage_by_cid[usage_by_cid.values == 1].index.values\n",
    "    return df[~df.customer_id.isin(cid_to_exclude)]\n",
    "\n",
    "\n",
    "df_multi = df_w_multi_customers(df)\n",
    "\n",
    "ti = time_it(\"Plotting distributions\")\n",
    "plot_distribution_for(df, 3, 0)\n",
    "plot_distribution_for(df, 10, 3)\n",
    "plot_distribution_for(df, 10, 10)\n",
    "plot_distribution_for(df, 10, 500)\n",
    "ti.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# MAU/WAU/DAU analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "freq = \"M\"\n",
    "cid_by_date = df[\"2019\":].pivot_table(\n",
    "    values=\"datetime\",\n",
    "    index=[\"customer_id\"],\n",
    "    columns=pd.Grouper(freq=freq),\n",
    "    aggfunc=\"any\",\n",
    ")\n",
    "# cid_sorted_by_sum = cid_by_date.T.sum().sort_values(ascending=False).index\n",
    "# cid_by_date = cid_by_date.sort_values(\"customer_id\")\n",
    "# cid_by_date.T[cid_sorted_by_sum[4:5]].plot()\n",
    "# cid_by_date.T.count().sort_values()\n",
    "# df_hc.pivot_table(index=[\"customer_id\"], columns=pd.Grouper(freq=freq), aggfunc=\"count\")[ \"customer_id\" ].T.plot(title=f\"customer {irange} by freq={freq}\", figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def cid_by_freq(df, freq):\n",
    "    return df[\"2019\":].pivot_table(\n",
    "        values=\"datetime\",\n",
    "        index=[\"customer_id\"],\n",
    "        columns=pd.Grouper(freq=freq),\n",
    "        aggfunc=\"any\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# cid_by_date.T.sum().sort_values(ascending=False)\n",
    "def print_freq(df, freq, cuteName, minUsage):\n",
    "    # minUsage should be inferred\n",
    "    c = cid_by_freq(df, freq).sum(axis=\"columns\")\n",
    "    print(f\"{cuteName}:{intcomma(len(c[c >= minUsage ]))}\")\n",
    "\n",
    "\n",
    "# NOTE: Could speed up significantly by removing\n",
    "# Single time users\n",
    "df_multi = df_w_multi_customers(df)\n",
    "print(f\"N:{intcomma(len(df.customer_id.value_counts()))}\")\n",
    "print(f\"N(>1):{intcomma(len(df_multi.customer_id.value_counts()))}\")\n",
    "print_freq(df_multi, \"M\", \"MAU_2\", 2)\n",
    "print_freq(df_multi, \"M\", \"MAU\", 5)\n",
    "print_freq(df_multi, \"W\", \"WAU\", 20)\n",
    "print_freq(df_multi, \"D\", \"DAU\", 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df.resample(\"M\").count()[\"datetime\"].plot(title=\"Total usage over time\")\n",
    "plt.show()\n",
    "\n",
    "df_tr = df[\"2019\"]\n",
    "customer_by_count = df_tr.customer_id.value_counts()\n",
    "irange = range(0,5)\n",
    "df_hc = df_tr[df_tr.customer_id.isin(customer_by_count.index[irange].values)]\n",
    "\n",
    "top_customer_by_month =  df_hc.pivot_table(\n",
    "        values=\"datetime\",\n",
    "        index=[\"customer_id\"],\n",
    "        columns=pd.Grouper(freq=\"M\"),\n",
    "        aggfunc=\"count\",\n",
    "    fill_value=0\n",
    "        ).T\n",
    "\n",
    "for kind in \"line area bar\".split():\n",
    "    top_customer_by_month.plot(title=\"Top customers usage over time\", kind=kind)\n",
    "    plt.show()\n",
    "print(f\"customer_by_count\\n{customer_by_count.head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
